{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing|Bag Of Words Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are solving sentiment analysis problem then that perticular data give it to model to \n",
    "covert that data in to numerical format we call it as vectors in NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example :-**\n",
    "    Suppose we have 3 postive sentences like as\n",
    "\n",
    "**sent-1 :- He is a good boy**\n",
    "\n",
    "**sent-2 :- She is a good girl**\n",
    "\n",
    "**sent-3 :- Boy and girls are good**\n",
    "\n",
    "(Note = During the text pre-processing 1st upon we lower the sentences because suppose their is\n",
    "capital H is in the sentence and small h in the sentence then this words are denoted seprately.\n",
    "e.g = In sentence when when we have capital He and small he is present then this is denoted seprately. when we have country names in that case we except this for county names.)\n",
    "\n",
    "(2nd step is to use steamming and Lemmatization on the text but here we  have simple 3 sentences so we dont use steamming and Lemmatization)\n",
    "\n",
    "**Stop Keywords :-** In this 3 sentences we have is,a,and,are words which are not important for \n",
    "data because when we are solving sentiment analysis and this kind of data is present lot but this is not a major data. major data in sentences is good,boy,girl and this kind of data is important.\n",
    "Remaining data like he,she,is,a,and,are not important so in stopwords we remove all the unimportant words/data from the sentences and keep only important words/data.\n",
    "\n",
    "**Stop keywords**\n",
    "\n",
    "**sent-1 :-** good, boy\n",
    "\n",
    "**sent-2 :-** good, girl\n",
    "\n",
    "**sent-3 :-** Boy girl good\n",
    "\n",
    "(In next step we create histrogram of important words. Histogram means we count frequencey of\n",
    "each and every important words in all the sentences.)\n",
    "\n",
    "|Words||Frequency|||\n",
    "|-----||---------||-|\n",
    "|good||3||good is present in all the 3 sentences|\n",
    "|boy||2||boy word is present in 2 sentences|\n",
    "|girl||2||girl word is present in 2 sentences|\n",
    "\n",
    "Remember when we are calculating the frequency of important words then they are not in order so we arange them in desending order and then we applay **Bag of words**. In bag of words we convert this important words in to vectors.\n",
    "\n",
    "Their are 2 types of Bag of words\n",
    "\n",
    "1] Binary Bag of word\n",
    "\n",
    "2] Bag of word\n",
    "\n",
    "**1] Binary Bag of Words**\n",
    "In Binary bag of words we have 1 and 0. We make important words are features.\n",
    "\n",
    "In 1st sentence good and boy words are present hence they mark as 1 in 1st sentence.\n",
    "\n",
    "In 2nd sentence good and girl word is present hence they mark as 1 in 2nd sentence.\n",
    "\n",
    "In 3rd sentence good, boy, girl is present hence they mark as 1 in 3rd sentence.\n",
    "\n",
    "If word is present we put 1 and if word is not present then we put 0. look into table\n",
    "\n",
    "|||f1||f2||f3|||\n",
    "|-||--||--||--||-|\n",
    "|||good||boy||girl||output|\n",
    "|sent-1||1||1||0||\n",
    "|sent-2||1||0||1||\n",
    "|sent-3||1||1||1||\n",
    "\n",
    "Hence sent-1 is represented by 1 1 0 vector\n",
    "\n",
    "sent-2 is represented by 1 0 1 vector\n",
    "\n",
    "sent-3 is represented by 1 1 1 vector\n",
    "\n",
    "(f1,f2 and f3 are independent features and output is dependent feature)\n",
    "\n",
    "**Disadvantage =** In sent-1 good is represented as 1 and boy is represented as 1 both the word having equal representation hence the semantic of this word is almost same. we are not able to derive which word is more important. simillerly in sent-2 and sent-3. To solve this prolem we use TF-IDF. \n",
    "\n",
    "**2] Bag of Words**\n",
    "Suppose we have sentences like as \n",
    "\n",
    "Sentence-1 = This boy is good boy\n",
    "Sentence-2 = This girl is good girl\n",
    "Sentence-3 = This are good boy and girl\n",
    "\n",
    "|||f1||f2||f3|||\n",
    "|-||--||--||--||-|\n",
    "|||good||boy||girl||output|\n",
    "|sent-1||1||2||0||\n",
    "|sent-2||1||0||2||\n",
    "|sent-3||1||1||1||\n",
    "\n",
    "In 1st Sentence good and boy word present at 1 and 2 times respectively.\n",
    "\n",
    "In 1st Sentence good and girl word present at 1 and 2 times respectively.\n",
    "\n",
    "In 3rd Sentence good, boy, girl word present at 1.\n",
    "\n",
    "(f1,f2 and f3 are independent features and output is dependent feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :- When are doing sentiment analysis then use bag of words but when dataset is huge then \n",
    "    we use word to vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
